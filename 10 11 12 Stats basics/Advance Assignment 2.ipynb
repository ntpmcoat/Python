{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3b6b6b",
   "metadata": {},
   "source": [
    "# Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n",
    "\n",
    "\n",
    "### Probability Mass Function (PMF):\n",
    "- The PMF is used for discrete random variables. \n",
    "- It gives the probability of the random variable taking on a specific value. \n",
    "- Mathematically, for a discrete random variable X, the PMF is denoted as P(X = x), where \"x\" is a particular value that X can take.\n",
    "- Example: Consider a fair six-sided die. Let X represent the outcome of a single roll of the die.\n",
    "\n",
    "### Probability Density Function (PDF):\n",
    "- The PDF is used for continuous random variables.\n",
    "- It provides the relative likelihood of the random variable falling within a certain range of values. Unlike the PMF, which gives the probability of specific values, the PDF gives the probability density over intervals.\n",
    "- Mathematically, for a continuous random variable X, the PDF is denoted as f(x), where \"x\" is a continuous value within the range of X.\n",
    "- Example:-Height of student\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879c4a1",
   "metadata": {},
   "source": [
    "# Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "- The Cumulative Density Function (CDF) is a concept used in probability and statistics to describe the distribution of a random variable.\n",
    "- It provides the probability that a random variable takes on a value less than or equal to a given value.\n",
    "- The CDF is denoted as F(x), where x is a specific value of the random variable.is defined as: F(x) = P(X ≤ x)\n",
    "\n",
    "\n",
    "============================================================\n",
    "##### Example:\n",
    "    Consider a fair six-sided die. Let X represent the outcome of a single roll of the die. The CDF of X would be:\n",
    "\n",
    "    F(x) = P(X ≤ x)\n",
    "\n",
    "    For the fair six-sided die, the probabilities are as follows:\n",
    "\n",
    "    P(X=1) = P(X=2) = P(X=3) = P(X=4) = P(X=5) = P(X=6) = 1/6 \n",
    "\n",
    "    So, the CDF of X would be:\n",
    "    F(1) = P(X ≤ 1)=  P(X=1) = 1/6\n",
    "    F(2) = P(X ≤ 2)=  P(X=1) +  P(X=2) = 1/6 + 1/6=  2/6\n",
    "    F(3) = P(X ≤ 3)=  P(X=1) +  P(X=2) +  P(X=3) = 1/6 + 1/6 + 1/6 =3/6\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    and so on\n",
    "\n",
    "================================\n",
    "##### Why CDF is used:\n",
    "\n",
    "- Calculating Probabilities : CDF allows calculating the probability of a random variable falling within a specific range.\n",
    "- Quantile Calculation : It helps find percentiles or quantiles, which represent the value below which a given percentage of observations fall.\n",
    "- Distribution Characteristics : The shape and behavior of the CDF provide insights into the characteristics of the probability distribution, such as symmetry, skewness, and tail behavior.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0f9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7cf3b3",
   "metadata": {},
   "source": [
    "# Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "### Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "##### Physical Measurements: \n",
    "- Natural phenomena like height, weight, and body temperature in populations often follow a normal distribution. \n",
    "- For example, the heights of adult humans tend to cluster around an average height, and taller or shorter heights become less common as you move away from the average.\n",
    "\n",
    "##### Test Scores:\n",
    "- In standardized testing, scores on exams like the SAT or IQ tests are often assumed to follow a normal distribution. \n",
    "- This assumption helps in setting reference ranges and evaluating performance.\n",
    "\n",
    "\n",
    "=> The parameters of the normal distribution are the mean (μ) and the standard deviation (σ).\n",
    "\n",
    "=> These parameters play a significant role in shaping the distribution:\n",
    "\n",
    "=> Mean (μ): \n",
    "- The mean determines the center of the distribution. \n",
    "- The highest point of the normal curve (peak) is located at the mean. \n",
    "- It also represents the expected value of the distribution.\n",
    "\n",
    "=> Standard Deviation (σ): \n",
    "- The standard deviation controls the spread or dispersion of the distribution.\n",
    "- A smaller standard deviation results in a narrower, taller curve, while a larger standard deviation results in a wider, flatter curve. The standard deviation gives an indication of how much individual data points vary from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408250f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9848f048",
   "metadata": {},
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n",
    "\n",
    "\n",
    "##### Here are some reasons why the normal distribution is important:\n",
    "\n",
    "1. Central Limit Theorem\n",
    "   - The normal distribution is a key concept in the Central Limit Theorem (CLT), which states that the distribution of sample means from any population approaches a normal distribution as the sample size increases, regardless of the shape of the original population distribution. This property is foundational in inferential statistics and hypothesis testing.\n",
    "\n",
    "2. Statistical Inference\n",
    "   - Many statistical methods, such as hypothesis tests and confidence intervals, assume that the data follows a normal distribution. When data approximates a normal distribution, these methods become more robust and accurate.\n",
    "\n",
    "3. Parameter Estimation\n",
    "   - The normal distribution often provides a reasonable approximation for the distribution of data in many situations. This makes parameter estimation (e.g., mean and variance) more reliable and efficient.\n",
    "\n",
    "##### Real-Life Examples of Normal Distribution:\n",
    "\n",
    "1. Height of Individuals\n",
    "   - The height of adult individuals in a population often follows a normal distribution, with the majority of people clustering around the average height.\n",
    "\n",
    "2. IQ Scores\n",
    "   - IQ scores are often assumed to follow a normal distribution, helping psychologists and educators understand cognitive abilities.\n",
    "\n",
    "3. Grades on Standardized Tests\n",
    "   - Scores on standardized tests like the SAT or GRE tend to be normally distributed, which informs how the tests are scored and interpreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cd7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6e0cd25",
   "metadata": {},
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n",
    "\n",
    "- The Bernoulli distribution is a discrete probability distribution that models a single binary (yes/no, success/failure) event. \n",
    "- It describes the probability of a single trial resulting in a success (usually denoted as 1) with a probability of \"p\" and a failure (usually denoted as 0) with a probability of \"q\" (where q = 1 - p).\n",
    "- Mathematically, the probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "     > P(X = x) = (n choose k)  *  p^x  *  q^(1 - x)\n",
    "\n",
    "            where:\n",
    "            - X is the random variable representing the outcome (1 for success, 0 for failure).\n",
    "            - \"x\" takes on values 0 or 1.\n",
    "            - \"p\" is the probability of success.\n",
    "            - \"q\" is the probability of failure.\n",
    "\n",
    "\n",
    "\n",
    "#### Example of Bernoulli Distribution\n",
    "\n",
    "      Consider flipping a fair coin. Let X represent the outcome of a single coin flip. If we define success as getting heads and failure as getting tails, then X follows a Bernoulli distribution. Let's say the probability of getting heads (success) is 0.5. The PMF of X would be:\n",
    "\n",
    "> P(X = 0) = (0.5)^0 * (0.5)^(1 - 0) = 0.5 (probability of tails)\n",
    "\n",
    "> P(X = 1) = (0.5)^1 * (0.5)^(1 - 1) = 0.5 (probability of heads)\n",
    "\n",
    "\n",
    "\n",
    "#### Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "1. Number of Trials:\n",
    "   - Bernoulli Distribution: Describes a single trial or event (1 trial).\n",
    "   - Binomial Distribution: Describes the number of successes in a fixed number of independent trials (multiple trials).\n",
    "\n",
    "2. Random Variables:\n",
    "   - Bernoulli Distribution: Has a single random variable that takes values 0 or 1.\n",
    "   - Binomial Distribution: Has a discrete random variable representing the count of successes in multiple trials.\n",
    "\n",
    "3. Parameters:\n",
    "   - Bernoulli Distribution: Has a single parameter \"p\" (probability of success).\n",
    "   - Binomial Distribution: Has two parameters: \"n\" (number of trials) and \"p\" (probability of success).\n",
    "\n",
    "4. Probability Mass Function (PMF):\n",
    "   - Bernoulli Distribution: P(X = 0) = q, P(X = 1) = p.\n",
    "   - Binomial Distribution: P(X = k) =  * p^k * q^(n - k).\n",
    "   - Binomial Distribution: P(X = k) = (n choose k) * p^k * q^(n - k).\n",
    "\n",
    "5. Use Cases:\n",
    "   - Bernoulli Distribution: Used for modeling a single binary event, like coin flips or pass/fail outcomes.\n",
    "   - Binomial Distribution: Used for modeling the number of successes in a fixed number of independent trials, such as counting the number\n",
    "    of heads in a series of coin flips.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ffd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49aff57",
   "metadata": {},
   "source": [
    "\n",
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n",
    "      z= (x−mean )/ std\n",
    "      ​ = (60-50)/10 \n",
    "      = 10/10 \n",
    "      = 1\n",
    "\n",
    "Using a standard normal distribution table we founnd that P(Z ≤ 1.0) is approximately 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given normally distributed dataset will be greater than 60 is:\n",
    "   > P(Z > 1.0) = 1 - P(Z ≤ 1.0) = 1 - 0.8413 ≈ 0.1587.\n",
    "    \n",
    "   > 15.87% or 0.1587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c8a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac6115aa",
   "metadata": {},
   "source": [
    "# Q7: Explain uniform Distribution with an example.\n",
    "\n",
    "- The uniform distribution is a probability distribution that describes a situation where all possible outcomes have an equal chance of occurring within a specified range. \n",
    "- In other words, in a uniform distribution, every value in the range is equally likely to be observed.\n",
    "- Mathematical Definition:\n",
    "  > The probability density function (PDF) of a uniform distribution on the interval [a, b] is given by:\n",
    "\n",
    "  > f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "\n",
    "  > f(x) = 0 otherwise\n",
    "\n",
    "      where:\n",
    "        a is the lower bound of the interval.\n",
    "        b is the upper bound of the interval.\n",
    "\n",
    "- Example of Uniform Distribution:\n",
    "   > Imagine rolling a fair six-sided die. The uniform distribution applies here because:\n",
    "\n",
    "   > Each face (1, 2, 3, 4, 5, 6) has an equal probability of 1/6.\n",
    "\n",
    "   > The probability of rolling any specific number is constant across the possible outcomes.\n",
    "  \n",
    "   > This uniform distribution reflects the fact that the die is \"fair\" and has no preference for any particular outcome.\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa4af72",
   "metadata": {},
   "source": [
    "# Q8: What is the z score? State the importance of the z score.\n",
    "\n",
    "- The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a distribution.\n",
    "- z= (x−mean )/ std\n",
    "     where \n",
    "        x ----> is the individual data point.\n",
    "        mean--> is the mean of the dataset.\n",
    "        std---> is the standard deviation of the dataset.\n",
    "\n",
    "Importance of the Z-Score:\n",
    "\n",
    "- Standardization: Z-scores standardize data, allowing comparisons between different datasets with varying units and scales.\n",
    "- Outlier Detection: Z-scores help identify outliers, which are data points significantly far from the mean. Typically, z-scores greater than a certain threshold indicate outliers.\n",
    "- Statistical Inference: Z-scores play a role in hypothesis testing and confidence interval calculations, aiding in making informed statistical conclusions.\n",
    "     \n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e782950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085fe7e3",
   "metadata": {},
   "source": [
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "\n",
    "- The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the shape of the original population distribution. \n",
    "- In simpler terms, the CLT explains how the distribution of sample averages becomes approximately normal, even when the individual data points themselves might not be normally distributed.\n",
    "\n",
    "  \n",
    "  \n",
    "  Significance of the Central Limit Theorem:\n",
    "\n",
    "- Normal Approximation: The CLT allows us to approximate the distribution of sample means (or other sample statistics) as normal, even when the population distribution itself is not normal. This property is crucial for applying various statistical techniques that assume normality.\n",
    "\n",
    "- Inference and Hypothesis Testing: The CLT is the foundation for many inferential statistical methods, such as hypothesis testing, confidence intervals, and z-tests. It enables statisticians to make inferences about population parameters using the normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b57df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d93e62",
   "metadata": {},
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem.\n",
    "\n",
    "- Random Sampling\n",
    "     > The samples must be drawn randomly from the population. This means that each observation in the sample is chosen independently and has an equal chance of being selected.\n",
    "\n",
    "- Independence\n",
    "     > The individual observations within each sample must be independent of each other. In other words, the value of one observation should not affect the value of another observation.\n",
    "\n",
    "- Sample Size\n",
    "     > The sample size should be sufficiently large. While there is no strict rule for what constitutes a \"sufficiently large\" sample size,a common guideline is that the sample size should be at least 30. However, for populations that are highly skewed or have heavy tails, a larger sample size may be necessary.\n",
    "\n",
    "- Finite Variance\n",
    "     > The population from which the samples are drawn must have a finite variance. This is because the CLT relies on the averaging of individual observations, and the variance affects the spread of the sample mean.\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
